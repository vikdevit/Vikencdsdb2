import pandas as pd
import numpy as np
import rpy2.robjects
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Utiliser un backend sans interface graphique (pas de Tkinter)
import os
from matplotlib.backends.backend_pdf import PdfPages
from fpdf import FPDF
from scipy import stats
from scipy.stats import chi2_contingency
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from rpy2.robjects import pandas2ri, r
from rpy2.robjects.packages import importr
#rpy2.robjects.r('install.packages("forecast")')
import psycopg2
from psycopg2 import sql
from psycopg2 import OperationalError
from psycopg2.extras import execute_values

# 1-Collecte, compr√©hension et audit de la qualit√© des donn√©es
# Chargement des donn√©es dans un dataframe
df = pd.read_csv("forestfires.csv")

# Affichage des premi√®res lignes
print(df.head())

print("##################################################################################")

# Affichage des informations sur le dataframe
print(df.info())

print("##################################################################################")

# Conversion en float de la colonne area et contr√¥le des premi√®res lignes de la colonne convertie area du dataframe
df["area"] = df["area"].str.replace(",", ".").astype(float)
print(f"Premi√®res valeurs de la colonne area converties en float: ")
print(df["area"].head())

# Conversion en category des colonnes month et day
df['month'] = df['month'].astype('category')
df['day'] = df['day'].astype('category')
print(df.info())

print("##################################################################################")

# Affichage du nombre de valeurs manquantes pour chaque colonne
missing_counts = np.sum(df.isnull(), axis=0)

for col, count in zip(df.columns, missing_counts):
    print(f"Colonne {col}: {count} valeur(s) manquante(s)")

print("##################################################################################")

# Recherche des valeurs distinctes et de leur nombre pour les colonnes month et day
columns_to_check = ["month", "day"]

for column in columns_to_check:
    unique_values = np.unique(df[column])
    unique_count = len(unique_values)
    print(f"Colonne {column}:")
    print(f"  Valeurs distinctes: {unique_values}")
    print(f"  Nombre de valeurs distinctes: {unique_count}\n")

print("##################################################################################")

# Recherche de la valeur minimale et maximale des composants du FWI system, du vent, des pr√©cipitations et de la surface br√ªl√©e
columns_to_check = ["FFMC", "DMC", "DC", "ISI", "temp", "RH", "wind", "rain", "area"]

result_minmax = df[columns_to_check].agg(["min", "max"])
print(result_minmax)

print("##################################################################################")

# Recherche des valeurs des composants au-dessus de la plage th√©orique de valeurs

# Plage th√©orique pour chaque indice FWI selon https://confluence.ecmwf.int/display/CEMS/User+Guide
theoretical_ranges = {
    "FFMC": (0, 101),   #The FFMC ranges from 0 to 101, where higher values indicate drier and more easily ignitable fuels.
    "DMC": (0, 1000),   #The DMC ranges from 0 to 1000, with higher values indicating drier conditions.
    "DC": (0, 1000), #The DC ranges from 0 to 1000, with higher values indicating drier conditions.
    "ISI": (0, 50), #The ISI ranges from 0 to 50, with higher values indicating a faster fire spread potential.
}

# Liste des colonnes √† v√©rifier
columns_to_check = ["FFMC", "DMC", "DC", "ISI"]

# V√©rification des valeurs au-dessus de la plage th√©orique pour les indices FWI
for column in theoretical_ranges:
    min_val, max_val = theoretical_ranges[column]

    # Recherche des lignes dont les valeurs sont au-dessus de la plage th√©orique
    above_max = df[df[column] > max_val]
    if not above_max.empty:
        print(f"\nLignes o√π la valeur de {column} d√©passe la plage th√©orique : {max_val}")
        print(f"Nombre de lignes : {above_max.shape[0]}")
        print("Indices des lignes d√©passant la plage th√©orique :")
        print(above_max.index.tolist())
    else:
        print(f"\nAucune ligne pour {column} qui d√©passe la plage th√©orique.")

print("##################################################################################")

# Recherche de lignes dont les valeurs ont un type non conforme √† leur colonne

# Dictionnaire des types attendus pour chaque colonne
expected_types = {
    "FFMC": float,
    "DMC": float,
    "DC": float,
    "ISI": float,
    "temp": float,
    "RH": int,
    "wind": float,
    "rain": float,
    "area": float
}

# Initialisation d'un drapeau pour indiquer s'il y a des valeurs non conformes
has_non_conforming_rows = False

# Boucle pour v√©rifier les types dans chaque colonne
for column, expected_type in expected_types.items():
    # Filtrer les lignes o√π le type n'est pas conforme
    non_conforming_rows = df[~df[column].apply(lambda x: isinstance(x, expected_type))]

    if not non_conforming_rows.empty:
        has_non_conforming_rows = True
        print(f"Colonnes avec valeurs non conformes dans '{column}':")
        print(non_conforming_rows, "\n")

# Si aucune ligne non conforme n'a √©t√© trouv√©e
if not has_non_conforming_rows:
    print("Aucune ligne trouv√©e de type non conforme avec la grandeur de la colonne.")

print("##################################################################################")

# Recherche des doublons et affichage des paires de lignes en doublon
duplicates = df[df.duplicated(keep=False)]  # Conserver toutes les occurrences des doublons

if duplicates.empty:
    print("Aucun doublon trouv√©.")
else:
    # R√©cup√©rer les indices des doublons
    duplicate_indices = duplicates.index.tolist()

    to_drop = []

    # Comparer chaque doublon avec les autres doublons
    for i in range(len(duplicate_indices)):
        for j in range(i + 1, len(duplicate_indices)):
            if df.iloc[duplicate_indices[i]].equals(df.iloc[duplicate_indices[j]]):
                print(f"Ligne num√©ro {duplicate_indices[i]} en doublon avec ligne num√©ro {duplicate_indices[j]}")
                to_drop.append(duplicate_indices[j])

print("##################################################################################")

# Premier affichage des statistiques descriptives sur le dataframe
pd.set_option('display.max_columns', None)
print(df.describe())

print("##################################################################################")

# 2-Alimentation, nettoyage et traitement des donn√©es

# Suppression des lignes en doublons
print("\nLignes √† supprimer (indices) :")
print(to_drop)

df_cleaned = df.drop(to_drop)

# Affichage des informations du nouveau dataframe
df_cleaned.info()

print("##################################################################################")

# Cr√©ation d'une nouvelle colonne 'season' pour stocker la saison correspondante
# D√©finition des saisons
season_mapping = {
    'jan': 'Hiver', 'feb': 'Hiver', 'dec': 'Hiver',
    'mar': 'Printemps', 'apr': 'Printemps', 'may': 'Printemps',
    'jun': '√ât√©', 'jul': '√ât√©', 'aug': '√ât√©',
    'sep': 'Automne', 'oct': 'Automne', 'nov': 'Automne'
}

df_cleaned['season'] = df_cleaned['month'].map(season_mapping).astype('category')
df_cleaned.info()

print("##################################################################################")

# Ajout d'une colonne calculant le BUI index pour en d√©duire le FWI index √† partir de la formule de https://wikifire.wsl.ch/tiki-index8720.html?page=Buildup+index
def calculate_bui(dmc, dc):
    condition = dmc <= 0.4 * dc
    bui = np.where(
        condition,
        (0.8 * dmc * dc) / (dmc + 0.4 * dc),
        dmc - (1 - (0.8 * dc) / (dmc + 0.4 * dc)) * (0.92 + (0.0114 * dmc) ** 1.7)
    )
    rounded_bui = np.round(bui, 1)
    return rounded_bui

df_cleaned['BUI'] = calculate_bui(df_cleaned['DMC'], df_cleaned['DC'])

# Caster la colonne 'BUI' en type 'float'
df_cleaned['BUI'] = df_cleaned['BUI'].astype('float')

# V√©rifier le type de la colonne
print(df_cleaned['BUI'].dtype)

# Affichage du DataFrame avec la nouvelle colonne
print("Premieres lignes du dataframe avec colonne BUI")
print(df_cleaned.head())

# Ajout d'une colonne estimant le FWI index √† partir d'une formule simplifi√©e selon publication de Van Wagner (1987)
def calculate_fwi(isi, bui):
    #return np.exp(0.05039 * isi) * bui ** 0.82 formule √† v√©rifier
    fwi = np.sqrt(0.1 * isi * bui)
    rounded_fwi = np.round(fwi, 1)
    return rounded_fwi

df_cleaned['FWI'] = calculate_fwi(df_cleaned['ISI'], df_cleaned['BUI'])

# Caster la colonne 'FWI' en type 'float'
df_cleaned['FWI'] = df_cleaned['FWI'].astype('float')

# V√©rifier le type de la colonne
print(df_cleaned['FWI'].dtype)

# Affichage du DataFrame avec les nouvelles colonnes
print("Premieres lignes du dataframe avec colonne FWI")
print(df_cleaned['FWI'])

# D√©sactiver la limitation d'affichage
pd.set_option('display.max_rows', None)

# Afficher la colonne FWI
print(df_cleaned['FWI'])

# Afficher la valeur max de la colonne FWI
print(f"La valeur maximale de FWI est: {df_cleaned['FWI'].max()}.")

# Ajouter un champ niveau de danger et un champ description du niveau selon https://climate-adapt.eea.europa.eu/en/metadata/indicators/fire-weather-index-monthly-mean-1979-2019
def get_danger_level(fwi):
    if fwi < 5.2:
        return "Tr√®s faible danger"
    elif 5.2 <= fwi < 11.2:
        return "Faible danger"
    elif 11.2 <= fwi < 21.3:
        return "Danger mod√©r√©"
    elif 21.3 <= fwi < 38.0:
        return "Fort danger"
    elif 38.0 <= fwi < 50.0:
        return "Tr√®s fort danger"
    else:
        return "Danger extr√™me"

def get_level_description(fwi):
    if fwi < 5.2:
        return "Peu ou pas de risque d'incendie"
    elif 5.2 <= fwi < 11.2:
        return "Risque d'incendie faible, contr√¥le possible"
    elif 11.2 <= fwi < 21.3:
        return "Risque d'incendie mod√©r√©, n√©cessite une attention accrue"
    elif 21.3 <= fwi < 38.0:
        return "Risque important, incendies se propagent rapidement"
    elif 38.0 <= fwi < 50.0:
        return "Conditions tr√®s s√®ches, risque de propagation rapide"
    else:
        return "Conditions extr√™mes, tr√®s grand risque d'incendie"

# Ajouter les nouvelles colonnes 'danger_level' et 'level_description' au DataFrame
df_cleaned['danger_level'] = df_cleaned['FWI'].apply(get_danger_level)
df_cleaned['level_description'] = df_cleaned['FWI'].apply(get_level_description)

# Caster les colonnes 'danger_level' et 'level_description' en type 'category'
df_cleaned['danger_level'] = df_cleaned['danger_level'].astype('category')
df_cleaned['level_description'] = df_cleaned['level_description'].astype('category')

# V√©rifier le type des nouvelles colonnes
print(df_cleaned['danger_level'].dtype)
print(df_cleaned['level_description'].dtype)

# Affichage du DataFrame avec les nouvelles colonnes
print(df_cleaned[['FWI', 'danger_level', 'level_description']])

print("##################################################################################")

# Comptage des lignes o√π 'area' est √©gal √† 0 et diff√©rent de 0
count_area_0 = (df_cleaned['area'] == 0).sum()  # Nombre de lignes avec area == 0
count_area_non_0 = (df_cleaned['area'] != 0).sum()  # Nombre de lignes avec area != 0

# Cr√©er un DataFrame pour ces comptages
data = {'Condition': ['area = 0', 'area != 0'], 'Count': [count_area_0, count_area_non_0]}
df_count = pd.DataFrame(data)

# Tracer le diagramme en barres
plt.figure(figsize=(6, 4))
sns.barplot(x='Condition', y='Count', data=df_count, palette='Blues')
plt.title("Nombre de lignes avec 'area' √©gal √† 0 et diff√©rent de 0")
plt.xlabel("Condition")
plt.ylabel("Nombre de lignes")
plt.show()

print("##################################################################################")

# Ajout d'une colonne pour transformation logarithmique de 'area' pour am√©liorer la normalit√©
df_cleaned['log_area'] = np.log1p(df_cleaned['area'])

print("##################################################################################")

# Cr√©ation de deux dataframe sous-ensembles de df_cleaned (area = 0 et area != 0)

# Filtrer les lignes o√π 'area' est √©gal √† 0
df_area_0 = df_cleaned[df_cleaned['area'] == 0]

# Filtrer les lignes o√π 'area' est diff√©rent de 0
df_area_non_0 = df_cleaned[df_cleaned['area'] != 0]

# Afficher les DataFrames r√©sultants
print("DataFrame avec 'area' = 0:")
print(df_area_0.head())

print("\nDataFrame avec 'area' != 0:")
print(df_area_non_0.head())

print("##################################################################################")

# 3-Analyse et Visualisation des donn√©es
# Analyses univari√©es
# üìÅ Cr√©ation du r√©pertoire pour les analyses univari√©es
save_dir = "analyse_distrib_univariee"
os.makedirs(save_dir, exist_ok=True)

# Mesure de l'aplatissement de chaque distribution (kurtosis)
# Cr√©ation du PDF
pdf = FPDF()
pdf.set_auto_page_break(auto=True, margin=15)
pdf.add_page()

# Titre du PDF
pdf.set_font("Arial", 'B', 16)
pdf.cell(200, 10, txt="Analyse de la Kurtosis et de la Distribution", ln=True, align="C")

# Liste des colonnes √† tester
columns_to_test = ["X", "Y", "FFMC", "DMC", "DC", "ISI", "BUI", "temp", "RH", "wind", "rain", "area", "log_area", "FWI"]

# Tester la kurtosis pour chaque colonne et √©crire dans le PDF
pdf.ln(10)  # espace apr√®s le titre

# Mettre en gras pour l'en-t√™te des colonnes
pdf.set_font("Arial", 'B', 12)
pdf.cell(60, 10, txt="Colonne", border=1, align="C")
pdf.cell(40, 10, txt="Kurtosis", border=1, align="C")
pdf.cell(90, 10, txt="Type de Distribution", border=1, align="C")
pdf.ln()

# Retour √† la police normale pour les r√©sultats
pdf.set_font("Arial", '', 12)

for col in columns_to_test:
    kurt = df_cleaned[col].kurtosis()

    # D√©terminer si la distribution est proche de normale (kurtosis proche de 3)
    if 2.5 <= kurt <= 3.5:
        dist_type = "Distribution proche de normale"
    elif kurt > 3:
        dist_type = "Distribution leptokurtique (queues lourdes)"
    else:
        dist_type = "Distribution platykurtique (queues l√©g√®res)"

    # Afficher le r√©sultat
    print(f"Colonne: {col}")
    print(f"Kurtosis: {kurt}")
    print(f"Type de distribution: {dist_type}")
    print("-" * 40)

    # Afficher chaque ligne avec les r√©sultats
    pdf.cell(60, 10, txt=col, border=1, align="C")
    pdf.cell(40, 10, txt=str(round(kurt, 2)), border=1, align="C")
    pdf.cell(90, 10, txt=dist_type, border=1, align="C")
    pdf.ln()

# Sauvegarder le PDF dans le r√©pertoire sp√©cifi√©
pdf_output_path = os.path.join(save_dir, "analyse_kurtosis_distrib.pdf")
pdf.output(pdf_output_path)

print(f"Le fichier PDF a √©t√© cr√©√© : {pdf_output_path}")

# Mesure de la distribution des donn√©es de chaque colonne par rapport √† une distribution normale (skewness)

# Cr√©ation du PDF
pdf = FPDF()
pdf.set_auto_page_break(auto=True, margin=15)
pdf.add_page()

# Titre du PDF
pdf.set_font("Arial", 'B', 16)
pdf.cell(200, 10, txt="Analyse de la Skewness et de la Distribution", ln=True, align="C")

# Liste des colonnes √† tester
columns_to_test = ["X", "Y", "FFMC", "DMC", "DC", "ISI", "BUI", "temp", "RH", "wind", "rain", "area", "log_area", "FWI"]

# Tester la skewness pour chaque colonne et √©crire dans le PDF
pdf.ln(10)  # espace apr√®s le titre

# Mettre en gras pour l'en-t√™te des colonnes
pdf.set_font("Arial", 'B', 12)
pdf.cell(60, 10, txt="Colonne", border=1, align="C")
pdf.cell(40, 10, txt="Skewness", border=1, align="C")
pdf.cell(90, 10, txt="Type de Distribution", border=1, align="C")
pdf.ln()

# Retour √† la police normale pour les r√©sultats
pdf.set_font("Arial", '', 12)

for col in columns_to_test:
    skew = df_cleaned[col].skew()

    # D√©terminer si la distribution est proche de normale (skewness proche de 0)
    if -0.5 <= skew <= 0.5:
        dist_type = "Distribution proche de normale"
    elif skew > 0:
        dist_type = "Distribution asym√©trique √† droite"
    else:
        dist_type = "Distribution asym√©trique √† gauche"

    # Afficher chaque ligne avec les r√©sultats
    pdf.cell(60, 10, txt=col, border=1, align="C")
    pdf.cell(40, 10, txt=str(round(skew, 2)), border=1, align="C")
    pdf.cell(90, 10, txt=dist_type, border=1, align="C")
    pdf.ln()

# Sauvegarder le PDF dans le r√©pertoire sp√©cifi√©
pdf_output_path = os.path.join(save_dir, "analyse_skewness_distrib.pdf")
pdf.output(pdf_output_path)

print(f"Le fichier PDF a √©t√© cr√©√© : {pdf_output_path}")

print("##################################################################################")

# Visualisation de la distribution des valeurs de chaque colonne

# Configuration du style des graphes
sns.set_style("whitegrid")

# S√©paration des variables num√©riques et cat√©goriques
num_vars = ["X", "Y", "FFMC", "DMC", "DC", "ISI", "BUI", "temp", "RH", "wind", "rain", "area", "log_area", "FWI"]
cat_vars = ["month", "day", "season", "danger_level", "level_description"]

# üìå **1. Visualisation des variables num√©riques**
for col in num_vars:
    plt.figure(figsize=(8, 5))
    sns.histplot(df_cleaned[col], bins=10, kde=True, color="royalblue")
    plt.title(f"Distribution de {col}", fontsize=14)
    plt.xlabel(col, fontsize=12)
    plt.ylabel("Fr√©quence", fontsize=12)

    # Sauvegarde des figures en PNG et PDF
    plt.savefig(os.path.join(save_dir, f"{col}.png"), format="png", dpi=300)
    plt.savefig(os.path.join(save_dir, f"{col}.pdf"), format="pdf", dpi=300)

    plt.close()  # Fermer la figure pour √©viter l'affichage multiple

# üìå **2. Visualisation des variables cat√©goriques**
for col in cat_vars:
    plt.figure(figsize=(8, 5))
    sns.countplot(x=df_cleaned[col], palette="viridis")
    plt.title(f"R√©partition de {col}", fontsize=14)
    plt.xlabel(col, fontsize=12)
    plt.ylabel("Nombre d'observations", fontsize=12)
    plt.xticks(rotation=45)

    # Sauvegarde des figures en PNG et PDF
    plt.savefig(os.path.join(save_dir, f"{col}.png"), format="png", dpi=300)
    plt.savefig(os.path.join(save_dir, f"{col}.pdf"), format="pdf", dpi=300)

    plt.close()  # Fermer la figure pour √©viter l'affichage multiple

print(f"Les graphiques sont enregistr√©s dans le dossier : {save_dir}")

# Affichage de plusieurs courbes sur une m√™me page

# Cr√©ation du r√©pertoire pour les graphiques
#save_dir = "analyse_distrib_univariee_subplots"
#os.makedirs(save_dir, exist_ok=True)

# Configuration du style des graphes
sns.set_style("whitegrid")

### üìå 1. Graphiques X et Y sur la m√™me figure ###
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))

sns.countplot(x=df_cleaned["X"], palette="viridis", ax=axes[0])
axes[0].set_title("R√©partition de X", fontsize=14)
axes[0].set_xlabel("X", fontsize=12)
axes[0].set_ylabel("Nombre d'observations", fontsize=12)

sns.countplot(x=df_cleaned["Y"], palette="viridis", ax=axes[1])
axes[1].set_title("R√©partition de Y", fontsize=14)
axes[1].set_xlabel("Y", fontsize=12)
axes[1].set_ylabel("Nombre d'observations", fontsize=12)

plt.tight_layout()
plt.savefig(os.path.join(save_dir, "X_Y.png"), format="png", dpi=300)
plt.savefig(os.path.join(save_dir, "X_Y.pdf"), format="pdf", dpi=300)
plt.close()

### üìå 2. Graphiques FFMC, DMC, DC, ISI, BUI, FWI sur la m√™me figure ###
fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))
fire_vars = ["FFMC", "DMC", "DC", "ISI", "BUI", "FWI"]

for i, col in enumerate(fire_vars):
    sns.histplot(df_cleaned[col], bins=10, kde=True, ax=axes[i // 2, i % 2], color="royalblue")
    axes[i // 2, i % 2].set_title(f"Distribution de {col}", fontsize=14)
    axes[i // 2, i % 2].set_xlabel(col, fontsize=12)
    axes[i // 2, i % 2].set_ylabel("Fr√©quence", fontsize=12)

plt.tight_layout()
plt.savefig(os.path.join(save_dir, "FFMC_DMC_DC_ISI_BUI_FWI.png"), format="png", dpi=300)
plt.savefig(os.path.join(save_dir, "FFMC_DMC_DC_ISI_BUI_FWI.pdf"), format="pdf", dpi=300)
plt.close()

### üìå 3. Graphiques temp, RH, wind, rain sur la m√™me figure ###
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))
weather_vars = ["temp", "RH", "wind", "rain"]

for i, col in enumerate(weather_vars):
    sns.histplot(df_cleaned[col], bins=10, kde=True, ax=axes[i // 2, i % 2], color="darkorange")
    axes[i // 2, i % 2].set_title(f"Distribution de {col}", fontsize=14)
    axes[i // 2, i % 2].set_xlabel(col, fontsize=12)
    axes[i // 2, i % 2].set_ylabel("Fr√©quence", fontsize=12)

plt.tight_layout()
plt.savefig(os.path.join(save_dir, "temp_RH_wind_rain.png"), format="png", dpi=300)
plt.savefig(os.path.join(save_dir, "temp_RH_wind_rain.pdf"), format="pdf", dpi=300)
plt.close()

print(f"Les graphiques sont enregistr√©s dans le dossier : {save_dir}")

# üìÅ Cr√©ation du r√©pertoire pour sauvegarder les graphiques
#save_dir = "analyse_distrib_univariee_area"
#os.makedirs(save_dir, exist_ok=True)

# üìä Comptage des valeurs o√π area = 0 et area > 0
df_count = pd.DataFrame({
    "Condition": ["Surface Br√ªl√©e = 0", "Surface Br√ªl√©e > 0"],
    "Count": [sum(df_cleaned["area"] == 0), sum(df_cleaned["area"] > 0)]
})

# üî• Tracer le diagramme en barres
plt.figure(figsize=(7, 5))
sns.barplot(x='Condition', y='Count', data=df_count, palette='Blues')

# üìå Personnalisation du graphique
plt.title("Nombre de lignes avec 'area' √©gal √† 0 et diff√©rent de 0", fontsize=14, fontweight='bold')
plt.xlabel("Condition", fontsize=12)
plt.ylabel("Nombre de lignes", fontsize=12)
plt.xticks(fontsize=11)
plt.yticks(fontsize=11)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# üìÇ Sauvegarde du graphique
file_path_png = os.path.join(save_dir, "area_distribution.png")
file_path_pdf = os.path.join(save_dir, "area_distribution.pdf")
plt.savefig(file_path_png, format="png", dpi=300)
plt.savefig(file_path_pdf, format="pdf", dpi=300)
plt.close()

print("##################################################################################")

# Statistiques descriptives

# üìÅ Cr√©ation du r√©pertoire pour sauvegarder les fichiers

save_dir = "desc_stats"
os.makedirs(save_dir, exist_ok=True)

# üìå Liste des regroupements de variables pour les pages du PDF
plots_groups = {
    "X_Y": ["X", "Y"],
    "FFMC_DMC_DC_ISI_BUI_FWI": ["FFMC", "DMC", "DC", "ISI", "BUI", "FWI"],
    "Temp_RH_Wind_Rain": ["temp", "RH", "wind", "rain"],
    "Area": ["area", "log_area"]
}

# üìÑ Cr√©ation du fichier PDF
pdf_path = os.path.join(save_dir, "boxplots_with_stats.pdf")
with PdfPages(pdf_path) as pdf:
    # üî• G√©n√©ration des boxplots
    for page_name, cols in plots_groups.items():
        fig, axes = plt.subplots(nrows=1, ncols=len(cols), figsize=(6 * len(cols), 6))

        # ‚úÖ S'assurer que axes est toujours une liste
        if len(cols) == 1:
            axes = [axes]  # Convertir en liste si une seule variable

        # üîÑ Cr√©ation des boxplots
        for i, col in enumerate(cols):
            ax = axes[i]
            sns.boxplot(y=df_cleaned[col], ax=ax, color="royalblue", width=0.5)

            # üìä Calcul des statistiques
            Q1 = df_cleaned[col].quantile(0.25)
            Q2 = df_cleaned[col].median()  # M√©diane
            Q3 = df_cleaned[col].quantile(0.75)
            Q4 = df_cleaned[col].max()
            mean_value = df_cleaned[col].mean()

            # üéØ Ajout des valeurs sur le graphique
            statist = {
                "Q1": Q1,
                "M√©diane (Q2)": Q2,
                "Q3": Q3,
                "Max (Q4)": Q4,
                "Moyenne": mean_value
            }

            # üìå Positionner les textes sur le graphique
            for j, (stat_name, value) in enumerate(statist.items()):
                ax.text(0, value, f"{stat_name}: {value:.2f}", ha='center', va='bottom',
                        fontsize=10, fontweight='bold', bbox=dict(facecolor='white', alpha=0.6))

            # üé® Ajout du titre et labels
            ax.set_title(f"Boxplot de {col}", fontsize=14, fontweight='bold')
            ax.set_ylabel(col, fontsize=12)
            ax.grid(axis='x', linestyle='--', alpha=0.7)

        plt.tight_layout()

        # üìå Sauvegarde en PDF
        pdf.savefig(fig)

        # üìå Sauvegarde en PNG
        png_path = os.path.join(save_dir, f"boxplot_{page_name}.png")
        plt.savefig(png_path, dpi=300)

        plt.close()

print(f"‚úÖ Boxplots sauvegard√©s dans {save_dir}.")

print("##################################################################################")

# üìè Calcul des statistiques descriptives avec Numpy
statistics = {}

for col in df_cleaned.select_dtypes(include=[np.number]).columns:
    # Calcul des quartiles et de l'IQR
    Q1 = np.percentile(df_cleaned[col], 25)
    Q3 = np.percentile(df_cleaned[col], 75)
    IQR = Q3 - Q1

    # Calcul de la limite des moustaches sup√©rieures
    whisker_upper = Q3 + 1.5 * IQR

    # V√©rification si Q4 (maximum) est un outlier
    max_value = np.max(df_cleaned[col])
    is_outlier = max_value > whisker_upper

    statist = {
        "Moyenne": np.mean(df_cleaned[col]),
        "M√©diane": np.median(df_cleaned[col]),
        "Variance": np.var(df_cleaned[col]),
        "√âcart type": np.std(df_cleaned[col]),
        "Minimum": np.min(df_cleaned[col]),
        "Q1 (25%)": Q1,
        "Q3 (75%)": Q3,
        "IQR": IQR,
        "Maximum": max_value,
        "Outlier (Q4)": "Oui" if is_outlier else "Non",
    }
    statistics[col] = statist

# üîπ Cr√©ation du DataFrame des statistiques
desc_stats_df = pd.DataFrame(statistics).T

# üìÑ Cr√©ation du fichier PDF et PNG pour sauvegarder
pdf_path = os.path.join(save_dir, "descriptive_statistics.pdf")
png_path = os.path.join(save_dir, "descriptive_statistics.png")

with PdfPages(pdf_path) as pdf:
    # üìä Tracer les statistiques sous forme de tableau
    fig, ax = plt.subplots(figsize=(10, 6))  # Taille du graphique pour le tableau
    ax.axis('off')
    ax.table(cellText=desc_stats_df.values, colLabels=desc_stats_df.columns, rowLabels=desc_stats_df.index,
             loc='center',
             cellLoc='center', colLoc='center', bbox=[0, 0, 1, 1])

    # üìå Sauvegarder le tableau en PDF
    pdf.savefig(fig)

    # üìå Sauvegarder le tableau en PNG
    plt.savefig(png_path, dpi=300)

    plt.close()

print(f"‚úÖ Statistiques descriptives sauvegard√©es dans {save_dir}.")

print("##################################################################################")

# Analyses bivari√©es

# D√©finir un r√©pertoire et le cr√©er si non encore existant
save_dir = "analyses_bivari√©es"
os.makedirs(save_dir, exist_ok=True)

# Visualisation de la distribution mensuelle de la surface br√ªl√©e sur le dataframe avec surface br√ªl√©e non nulle

# Liste des mois dans l'ordre du calendrier
mois_ordre = ['jan', 'feb', 'mar', 'apr', 'may', 'jun',
              'jul', 'aug', 'sep', 'oct', 'nov', 'dec']

# 1. Boxplot de la distribution de la surface br√ªl√©e par mois
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_area_non_0, x='month', y='area', palette="Set2", order=mois_ordre)
plt.title("Distribution Mensuelle de la Surface Br√ªl√©e")
plt.xlabel("Mois")
plt.ylabel("Surface Br√ªl√©e (area)")
plt.xticks(rotation=45)
plt.tight_layout()

# Sauvegarde du graphique en .png et .pdf
boxplot_filename_png = os.path.join(save_dir, "boxplot_surface_brulee.png")
boxplot_filename_pdf = os.path.join(save_dir, "boxplot_surface_brulee.pdf")
plt.savefig(boxplot_filename_png)
plt.savefig(boxplot_filename_pdf)
plt.close()

# 2. Diagramme en barres pour la somme de la surface br√ªl√©e par mois
monthly_sum = df_area_non_0.groupby('month')['area'].sum().reset_index()  # Somme de la surface br√ªl√©e par mois
plt.figure(figsize=(10, 6))
sns.barplot(data=monthly_sum, x='month', y='area', palette="Set3", order=mois_ordre)
plt.title("Surface Br√ªl√©e Totale par Mois")
plt.xlabel("Mois")
plt.ylabel("Surface Br√ªl√©e Totale")
plt.xticks(rotation=45)
plt.tight_layout()

# Sauvegarde du graphique en .png et .pdf
barplot_sum_filename_png = os.path.join(save_dir, "barplot_sum_surface_brulee.png")
barplot_sum_filename_pdf = os.path.join(save_dir, "barplot_sum_surface_brulee.pdf")
plt.savefig(barplot_sum_filename_png)
plt.savefig(barplot_sum_filename_pdf)
plt.close()

# 3. Diagramme en barres pour la moyenne de la surface br√ªl√©e par mois
monthly_avg = df_area_non_0.groupby('month')['area'].mean().reset_index()  # Moyenne de la surface br√ªl√©e par mois
plt.figure(figsize=(10, 6))
sns.barplot(data=monthly_avg, x='month', y='area', palette="Set3", order=mois_ordre)
plt.title("Surface Br√ªl√©e Moyenne par Mois")
plt.xlabel("Mois")
plt.ylabel("Surface Br√ªl√©e Moyenne")
plt.xticks(rotation=45)
plt.tight_layout()

# Sauvegarde du graphique en .png et .pdf
barplot_avg_filename_png = os.path.join(save_dir, "barplot_avg_surface_brulee.png")
barplot_avg_filename_pdf = os.path.join(save_dir, "barplot_avg_surface_brulee.pdf")
plt.savefig(barplot_avg_filename_png)
plt.savefig(barplot_avg_filename_pdf)
plt.close()

print("Les graphiques ont √©t√© enregistr√©s dans le r√©pertoire 'analyses_bivariees'.")

# Visualisation de la fr√©quence des incendies par mois
plt.figure(figsize=(10, 6))
sns.countplot(data=df_area_non_0, x='month', palette="Set2", order=mois_ordre)
plt.title("Fr√©quence des Incendies par Mois")
plt.xlabel("Mois")
plt.ylabel("Nombre d'Incendies")
plt.xticks(rotation=45)
plt.tight_layout()

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/frequence_incendies_par_mois.png")
plt.savefig(f"{save_dir}/frequence_incendies_par_mois.pdf")
plt.close()

# Visualisation de la fr√©quence des incendies par saison
# Comptage du nombre d'incendies par saison
season_counts = df_area_non_0['season'].value_counts().reindex(['Hiver', 'Printemps', '√ât√©', 'Automne'])

# üìä Cr√©ation du diagramme en barres
plt.figure(figsize=(8, 6))
sns.barplot(x=season_counts.index, y=season_counts.values, palette="coolwarm")
plt.title("Fr√©quence des Incendies par Saison")
plt.xlabel("Saison")
plt.ylabel("Nombre d'Incendies")
plt.xticks(rotation=0)
plt.tight_layout()

# üìÇ Sauvegarde du graphique en PNG et PDF
season_freq_png = os.path.join(save_dir, "frequence_incendies_saisons.png")
season_freq_pdf = os.path.join(save_dir, "frequence_incendies_saisons.pdf")
plt.savefig(season_freq_png)
plt.savefig(season_freq_pdf)
plt.close()

print("Le graphique de la fr√©quence des incendies par saison a √©t√© enregistr√© dans 'analyses_bivariees'.")

# Visualisation de la surface br√ªl√©e en fonction des coordonn√©es X et Y

# Cr√©ez une figure 3D
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# D√©finir les donn√©es
x = df_area_non_0['X']  # Coordonn√©e X
y = df_area_non_0['Y']  # Coordonn√©e Y
z = df_area_non_0['area']  # Surface br√ªl√©e (area)

# Cr√©er un scatter plot en 3D
ax.scatter(x, y, z, c=z, cmap='viridis', marker='o', edgecolors='k', alpha=0.7)

# Ajouter les titres et les labels
ax.set_title('Visualisation 3D de la Surface Br√ªl√©e en fonction de X et Y', fontsize=16)
ax.set_xlabel('Coordonn√©e X', fontsize=12)
ax.set_ylabel('Coordonn√©e Y', fontsize=12)
ax.set_zlabel('Surface Br√ªl√©e (area)', fontsize=12)

# Afficher la colorbar pour indiquer l'intensit√© des surfaces br√ªl√©es
cbar = plt.colorbar(ax.collections[0], ax=ax, shrink=0.5, aspect=10)
cbar.set_label('Surface Br√ªl√©e', rotation=270, labelpad=20)

# Enregistrer le graphique en .png et .pdf dans le r√©pertoire
png_path = os.path.join(save_dir, 'visualisation_surface_brulee.png')
pdf_path = os.path.join(save_dir, 'visualisation_surface_brulee.pdf')

fig.savefig(png_path, format='png', bbox_inches='tight')
fig.savefig(pdf_path, format='pdf', bbox_inches='tight')

# Fermer la figure apr√®s enregistrement
plt.close()

# Message de confirmation
print(f"Le graphique a √©t√© enregistr√© dans le r√©pertoire : {save_dir}")
print(f"Fichier .png enregistr√© sous : {png_path}")
print(f"Fichier .pdf enregistr√© sous : {pdf_path}")

# Version avec surface de la visualisation de la surface br√ªl√©e en fonction des coordonn√©es X et Y
# Cr√©ez une figure 3D
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# D√©finir les donn√©es
x = df_area_non_0['X']  # Coordonn√©e X
y = df_area_non_0['Y']  # Coordonn√©e Y
z = df_area_non_0['area']  # Surface br√ªl√©e (area)

# Cr√©er une grille pour une meilleure repr√©sentation de la surface
X_grid, Y_grid = np.meshgrid(np.unique(x), np.unique(y))

# Interpolation des valeurs de surface pour obtenir des valeurs z sur la grille
Z_grid = np.zeros(X_grid.shape)
for i in range(X_grid.shape[0]):
    for j in range(X_grid.shape[1]):
        # Correspondance de X, Y avec les valeurs z dans le dataframe
        idx = (x == X_grid[i, j]) & (y == Y_grid[i, j])
        if np.any(idx):
            Z_grid[i, j] = z[idx].iloc[0]  # Prendre la valeur de la surface br√ªl√©e (area)

# Cr√©er une surface lisse avec `plot_surface`
surf = ax.plot_surface(X_grid, Y_grid, Z_grid, cmap='viridis', edgecolor='none', alpha=0.7)

# Ajouter les titres et les labels
ax.set_title('Repr√©sentation de la Surface Br√ªl√©e en fonction de X et Y', fontsize=16)
ax.set_xlabel('Coordonn√©e X', fontsize=12)
ax.set_ylabel('Coordonn√©e Y', fontsize=12)
ax.set_zlabel('Surface Br√ªl√©e (area)', fontsize=12)

# Afficher la colorbar pour indiquer l'intensit√© des surfaces br√ªl√©es
cbar = plt.colorbar(surf, ax=ax, shrink=0.5, aspect=10)
cbar.set_label('Surface Br√ªl√©e', rotation=270, labelpad=20)

# Enregistrer le graphique en .png et .pdf dans le r√©pertoire
png_path = os.path.join(save_dir, 'surface_brulee_3d.png')
pdf_path = os.path.join(save_dir, 'surface_brulee_3d.pdf')

# Enregistrer les fichiers .png et .pdf
fig.savefig(png_path, format='png', bbox_inches='tight')
fig.savefig(pdf_path, format='pdf', bbox_inches='tight')

# Fermer la figure apr√®s l'enregistrement pour √©viter toute interf√©rence
plt.close(fig)

# Afficher un message de confirmation
print(f"Le graphique a √©t√© enregistr√© dans le r√©pertoire : {save_dir}")
print(f"Fichier .png enregistr√© sous : {png_path}")
print(f"Fichier .pdf enregistr√© sous : {pdf_path}")

# Visualiser la surface br√ªl√©e en fonction de la temp√©rature
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_area_non_0, x='temp', y='area', alpha=0.6, edgecolor=None, color="royalblue")
plt.title("Surface Br√ªl√©e en Fonction de la Temp√©rature")
plt.xlabel("Temp√©rature (¬∞C)")
plt.ylabel("Surface Br√ªl√©e (ha)")
plt.grid(True)
plt.tight_layout()

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_vs_temperature.png")
plt.savefig(f"{save_dir}/surface_brulee_vs_temperature.pdf")
plt.close()

# Visualistation avec axe secondaire log area
plt.figure(figsize=(10, 6))

# Axe principal : area vs temperature
ax1 = sns.scatterplot(data=df_area_non_0, x='temp', y='area',
                      alpha=0.6, edgecolor=None, color="royalblue", label="Surface Br√ªl√©e (ha)")

# Cr√©ation d'un axe secondaire
ax2 = ax1.twinx()
sns.scatterplot(data=df_area_non_0, x='temp', y='log_area',
                alpha=0.6, edgecolor=None, color="darkorange", label="log(Surface Br√ªl√©e)")

# Titres et labels
ax1.set_xlabel("Temp (¬∞C)")
ax1.set_ylabel("Surface Br√ªl√©e (ha)", color="royalblue")
ax2.set_ylabel("log(Surface Br√ªl√©e)", color="darkorange")

# Ajout d'une grille et d'un titre
plt.title("Surface Br√ªl√©e et log(Surface Br√ªl√©e) en Fonction de la Temp√©rature")
ax1.grid(True, linestyle="--", alpha=0.5)

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_et_surfacelog_vs_temperature.png")
plt.savefig(f"{save_dir}/surface_brulee_etsurfacelog_vs_temperature.pdf")
plt.close()

# Visualiser la surface br√ªl√©e en fonction de l'humidit√© relative
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_area_non_0, x='RH', y='area', alpha=0.6, edgecolor=None, color="royalblue")
plt.title("Surface Br√ªl√©e en Fonction de l'humidit√© relative")
plt.xlabel("RH (%)")
plt.ylabel("Surface Br√ªl√©e (ha)")
plt.grid(True)
plt.tight_layout()

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_vs_humidite_relative.png")
plt.savefig(f"{save_dir}/surface_brulee_vs_humidite_relative.pdf")
plt.close()

# Visualistation avec axe secondaire log area
plt.figure(figsize=(10, 6))

# Axe principal : area vs humidit√© relative
ax1 = sns.scatterplot(data=df_area_non_0, x='RH', y='area',
                      alpha=0.6, edgecolor=None, color="royalblue", label="Surface Br√ªl√©e (ha)")

# Cr√©ation d'un axe secondaire
ax2 = ax1.twinx()
sns.scatterplot(data=df_area_non_0, x='RH', y='log_area',
                alpha=0.6, edgecolor=None, color="darkorange", label="log(Surface Br√ªl√©e)")

# Titres et labels
ax1.set_xlabel("HR (%)")
ax1.set_ylabel("Surface Br√ªl√©e (ha)", color="royalblue")
ax2.set_ylabel("log(Surface Br√ªl√©e)", color="darkorange")

# Ajout d'une grille et d'un titre
plt.title("Surface Br√ªl√©e et log(Surface Br√ªl√©e) en Fonction de la Temp√©rature")
ax1.grid(True, linestyle="--", alpha=0.5)

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_et_surfacelog_vs_hr.png")
plt.savefig(f"{save_dir}/surface_brulee_etsurfacelog_vs_hr.pdf")
plt.close()

# Visualiser la surface br√ªl√©e en fonction du vent
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_area_non_0, x='wind', y='area', alpha=0.6, edgecolor=None, color="royalblue")
plt.title("Surface Br√ªl√©e en Fonction du vent")
plt.xlabel("vent (km/h)")
plt.ylabel("Surface Br√ªl√©e (ha)")
plt.grid(True)
plt.tight_layout()

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_vs_vent.png")
plt.savefig(f"{save_dir}/surface_brulee_vs_vent.pdf")
plt.close()

# Visualistation avec axe secondaire log area
plt.figure(figsize=(10, 6))

# Axe principal : area vs wind
ax1 = sns.scatterplot(data=df_area_non_0, x='wind', y='area',
                      alpha=0.6, edgecolor=None, color="royalblue", label="Surface Br√ªl√©e (ha)")

# Cr√©ation d'un axe secondaire
ax2 = ax1.twinx()
sns.scatterplot(data=df_area_non_0, x='wind', y='log_area',
                alpha=0.6, edgecolor=None, color="darkorange", label="log(Surface Br√ªl√©e)")

# Titres et labels
ax1.set_xlabel("Vent (km/h)")
ax1.set_ylabel("Surface Br√ªl√©e (ha)", color="royalblue")
ax2.set_ylabel("log(Surface Br√ªl√©e)", color="darkorange")

# Ajout d'une grille et d'un titre
plt.title("Surface Br√ªl√©e et log(Surface Br√ªl√©e) en Fonction du Vent")
ax1.grid(True, linestyle="--", alpha=0.5)

# üìÇ Sauvegarde du graphique
plt.savefig(f"{save_dir}/surface_brulee_et_surfacelog_vs_vent.png")
plt.savefig(f"{save_dir}/surface_brulee_et_surfacelog_vs_vent.pdf")
plt.close()

# Visualisation d'autres pairplots

# üìå Fonction de sauvegarde pour les heatmaps et pairplots
def save_figure(fig, file_name, save_dir):
    """Sauvegarde les figures sous format PNG et PDF."""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)  # Cr√©er le r√©pertoire s'il n'existe pas

    fig.savefig(os.path.join(save_dir, f"{file_name}.png"), bbox_inches='tight')
    fig.savefig(os.path.join(save_dir, f"{file_name}.pdf"), bbox_inches='tight')
    plt.close(fig)

# Liste des colonnes num√©riques √† analyser
# üü¢ D√©finition des groupes de colonnes
colonnes_normales = ['X', 'Y', 'BUI', 'temp']
colonnes_asymetriques = ['FFMC', 'DMC', 'DC', 'ISI', 'RH', 'wind', 'rain']

# Affichage du pairplot pour le cas o√π la surface br√ªl√©e est non nulle
pairplot_burned = sns.pairplot(df_area_non_0[colonnes_normales+ colonnes_asymetriques + ['log_area']])
plt.suptitle("Pairplot - Surface br√ªl√©e non nulle", y=1.02)
save_figure(pairplot_burned.fig, "pairplot_burned", save_dir)

# Affichage du pairplot pour le cas o√π la surface br√ªl√©e est nulle
pairplot_no_burn = sns.pairplot(df_area_0[colonnes_normales + colonnes_asymetriques])
plt.suptitle("Pairplot - Surface br√ªl√©e nulle", y=1.02)
save_figure(pairplot_burned.fig, "pairplot_no_burn", save_dir)

print("Les pairplots ont √©t√© g√©n√©r√©s et sauvegard√©s.")

# Trac√© des valeurs min, max et moyennes du FWI en fonction du mois

df_grouped = df_cleaned.groupby('month')['FWI'].agg(['max', 'min', 'mean'])

# Assurez-vous que les mois sont ordonn√©s
df_grouped = df_grouped.sort_index()

# Cr√©ation de la figure et des axes
plt.figure(figsize=(10, 6))

# Tracer les trois courbes
plt.plot(df_grouped.index, df_grouped['max'], label='FWI Max', color='red', marker='o')
plt.plot(df_grouped.index, df_grouped['min'], label='FWI Min', color='blue', marker='o')
plt.plot(df_grouped.index, df_grouped['mean'], label='FWI Moyen', color='green', marker='o')

# Ajouter des labels, un titre et une l√©gende
plt.xlabel('Mois')
plt.ylabel('FWI')
plt.title('FWI Max, Min et Moyen en fonction du mois')

# R√©ordonner les mois de 1 √† 12 sur l'axe x
mois_ordre = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
plt.xticks(ticks=df_grouped.index, labels=mois_ordre)

# Ajouter la l√©gende
plt.legend()

# Sauvegarder le graphique sous .png et .pdf
plt.savefig(f'{save_dir}/fwi_courbes_en_fonction_mois_calendaire.png')
plt.savefig(f'{save_dir}/fwi_courbes_en_fonction_mois_calendaire.pdf')
plt.close()

# Analyses multivari√©es

# D√©finir un r√©pertoire et le cr√©er si non encore existant
save_dir = "analyses_multivari√©es"
os.makedirs(save_dir, exist_ok=True)

# üü¢ D√©finition des groupes de colonnes
colonnes_normales = ['X', 'Y', 'BUI', 'temp']
colonnes_asymetriques = ['FFMC', 'DMC', 'DC', 'ISI', 'RH', 'wind', 'rain']

# üìä Matrices de corr√©lation
correlation_pearson = df_cleaned[['log_area']+colonnes_normales].corr(method='pearson')  # (Normales vs Normales)
correlation_spearman_asym = df_cleaned[['log_area']+colonnes_asymetriques].corr(method='spearman')  # (Asym√©triques vs Asym√©triques)
correlation_spearman_mixed = df_cleaned[['log_area']+colonnes_normales + colonnes_asymetriques].corr(method='spearman')  # (Tout en Spearman)

# üìå Affichage des matrices
print("\nüîπ Matrice de Corr√©lation Pearson (Colonnes Normales) :\n", correlation_pearson)
print("\nüîπ Matrice de Corr√©lation Spearman (Colonnes Asym√©triques) :\n", correlation_spearman_asym)
print("\nüîπ Matrice de Corr√©lation Spearman (M√©lange Normales & Asym√©triques) :\n", correlation_spearman_mixed)

# üî• Cr√©ation des heatmaps
fig, axes = plt.subplots(1, 3, figsize=(25, 7))

# üü¢ Heatmap Pearson (Normales vs Normales)
sns.heatmap(correlation_pearson, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5, ax=axes[0])
axes[0].set_title("üîπ Matrice de Corr√©lation de Pearson (Colonnes Normales)")

# üî¥ Heatmap Spearman (Asym√©triques vs Asym√©triques)
sns.heatmap(correlation_spearman_asym, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5, ax=axes[1])
axes[1].set_title("üîπ Matrice de Corr√©lation de Spearman (Colonnes Asym√©triques)")

# üîÑ Heatmap Spearman (M√©lange Normales et Asym√©triques)
sns.heatmap(correlation_spearman_mixed, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5, ax=axes[2])
axes[2].set_title("üîπ Matrice de Corr√©lation de Spearman (Tout)")

# üìÇ Sauvegarde des figures
plt.tight_layout()
plt.savefig(f"{save_dir}/correlation_heatmaps.png")
plt.savefig(f"{save_dir}/correlation_heatmaps.pdf")
plt.close()

# Poursuite analyses multivari√©es en distinguant les cas surface br√ªl√©e nulle et les cas surface brul√©e non nulle

# D√©finir un r√©pertoire et le cr√©er si non encore existant
save_dir = "analyses_multivariees_surface_brulee_0_et_non_0"
os.makedirs(save_dir, exist_ok=True)

# Statistiques descriptives pour les sous-groupes
print("Statistiques descriptives - Surface br√ªl√©e non nulle:")
print(df_area_non_0.describe())

print("\nStatistiques descriptives - Surface br√ªl√©e nulle:")
print(df_area_0.describe())

def save_heatmap(heatmap, file_name, save_dir):
    """Sauvegarde les heatmaps sous format PNG et PDF."""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)  # Cr√©er le r√©pertoire s'il n'existe pas

    plt.savefig(os.path.join(save_dir, f"{file_name}.png"), bbox_inches='tight')
    plt.savefig(os.path.join(save_dir, f"{file_name}.pdf"), bbox_inches='tight')
    plt.close()

# Liste des colonnes num√©riques √† analyser
variables_numeriques = ['X', 'Y', 'BUI', 'temp', 'FFMC', 'DMC', 'DC', 'ISI', 'RH', 'wind', 'rain']

# Dictionnaire pour stocker les r√©sultats de normalit√©
normality_results = {"brul√©": {}, "non_brul√©": {}}

# V√©rification de la normalit√© pour chaque variable dans chaque sous-ensemble
for var in variables_numeriques:
    # Test de Shapiro-Wilk pour la normalit√©
    p_value_non_0 = stats.shapiro(df_area_non_0[var])[1] if len(df_area_non_0[var]) > 3 else 1
    p_value_0 = stats.shapiro(df_area_0[var])[1] if len(df_area_0[var]) > 3 else 1

    normality_results["brul√©"][var] = p_value_non_0 > 0.05  # True si normal, False sinon
    normality_results["non_brul√©"][var] = p_value_0 > 0.05

# S√©paration dynamique des colonnes normales et asym√©triques
colonnes_normales_brule = [var for var, is_normal in normality_results["brul√©"].items() if is_normal]
colonnes_asymetriques_brule = [var for var, is_normal in normality_results["brul√©"].items() if not is_normal]

colonnes_normales_non_brule = [var for var, is_normal in normality_results["non_brul√©"].items() if is_normal]
colonnes_asymetriques_non_brule = [var for var, is_normal in normality_results["non_brul√©"].items() if not is_normal]

# Cr√©ation du r√©pertoire de sauvegarde
#save_dir = "analyses_multivariees_surface_brulee_0_et_non_0"

# üìå Corr√©lation Pearson pour les colonnes normales
if colonnes_normales_brule:
    pearson_corr_burned = df_area_non_0[['log_area']+colonnes_normales_brule].corr(method='pearson')
    plt.figure(figsize=(10, 6))
    sns.heatmap(pearson_corr_burned, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5)
    plt.title("Heatmap Corr√©lation Pearson - Surface br√ªl√©e non nulle")
    save_heatmap(plt, "pearson_corr_burned", save_dir)

if colonnes_normales_non_brule:
    pearson_corr_no_burn = df_area_0[colonnes_normales_non_brule].corr(method='pearson')
    plt.figure(figsize=(10, 6))
    sns.heatmap(pearson_corr_no_burn, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5)
    plt.title("Heatmap Corr√©lation Pearson - Surface br√ªl√©e nulle")
    save_heatmap(plt, "pearson_corr_no_burn", save_dir)

# üìå Corr√©lation Spearman pour les colonnes asym√©triques
if colonnes_asymetriques_brule:
    spearman_corr_burned = df_area_non_0[['log_area']+colonnes_asymetriques_brule].corr(method='spearman')
    plt.figure(figsize=(10, 6))
    sns.heatmap(spearman_corr_burned, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5)
    plt.title("Heatmap Corr√©lation Spearman - Surface br√ªl√©e non nulle")
    save_heatmap(plt, "spearman_corr_burned", save_dir)

if colonnes_asymetriques_non_brule:
    spearman_corr_no_burn = df_area_0[colonnes_asymetriques_non_brule].corr(method='spearman')
    plt.figure(figsize=(10, 6))
    sns.heatmap(spearman_corr_no_burn, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5)
    plt.title("Heatmap Corr√©lation Spearman - Surface br√ªl√©e nulle")
    save_heatmap(plt, "spearman_corr_no_burn", save_dir)

print("Les heatmaps ont √©t√© g√©n√©r√©es et sauvegard√©es.")

# Statistiques inf√©rentielles pour √©tudier l'influence des colonnes sur la surface br√ªl√©e

# D√©finir un r√©pertoire et le cr√©er si non encore existant
save_dir = "statistiques_inf√©rentielles"
os.makedirs(save_dir, exist_ok=True)

# Fonction pour sauvegarder les r√©sultats et graphiques dans un PDF
def save_results_to_pdf(results, save_dir, file_name="results_stats_inferentielles_tmw.pdf"):
    # Cr√©er un PDF
    pdf_path = os.path.join(save_dir, file_name)

    # D√©finir le document PDF
    doc = SimpleDocTemplate(pdf_path, pagesize=letter)

    # D√©finir les styles de texte pour le PDF
    styles = getSampleStyleSheet()
    style_normal = styles['Normal']
    style_heading = styles['Heading1']

    # Cr√©er une liste pour les √©l√©ments du document (texte et images)
    story = []

    # Ajouter un titre √† la premi√®re page
    title = Paragraph("Analyse des tests statistiques - R√©sultats", style_heading)
    story.append(title)
    story.append(Spacer(1, 12))  # Espacement apr√®s le titre

    # Ajouter les r√©sultats de chaque test au PDF
    for result in results:
        # Ajouter chaque r√©sultat au PDF sous forme de paragraphe
        paragraph = Paragraph(result, style_normal)
        story.append(paragraph)
        story.append(Spacer(1, 12))  # Espacement entre les paragraphes

    # Sauvegarder le PDF
    doc.build(story)

# Variables √† tester
variables = ['X', 'Y', 'BUI', 'temp', 'FFMC', 'DMC', 'DC', 'ISI', 'RH', 'wind']

# Pour stocker les r√©sultats
test_results = []

# Analyser la distribution et appliquer les tests
for var in variables:
    # Histogramme de la distribution pour les deux groupes
    plt.figure(figsize=(8, 5))
    sns.histplot(df_area_non_0[var], kde=True, color='blue', label='Surface br√ªl√©e non nulle')
    sns.histplot(df_area_0[var], kde=True, color='red', label='Surface br√ªl√©e nulle')
    plt.legend()
    plt.title(f"Distribution de {var} pour chaque groupe")

    # Sauvegarder l'histogramme dans le PDF
    plt.savefig(os.path.join(save_dir, f"{var}_distribution.png"))
    plt.close()

    # Test de normalit√© pour chaque groupe
    _, p_burned = stats.shapiro(df_area_non_0[var])
    _, p_no_burn = stats.shapiro(df_area_0[var])

    test_result = f"Test de normalit√© pour {var}:\n  p-value (Surface br√ªl√©e non nulle) : {p_burned:.3f}\n  p-value (Surface br√ªl√©e nulle) : {p_no_burn:.3f}"
    test_results.append(test_result)

    # Si les deux groupes sont normalement distribu√©s, utiliser le t-test
    if p_burned > 0.05 and p_no_burn > 0.05:
        t_stat, p_value = stats.ttest_ind(df_area_non_0[var], df_area_0[var])
        result = f"T-test pour {var} - Statistique t : {t_stat:.3f}, p-value : {p_value:.3f}"
        if p_value < 0.05:
            result += "\nIl y a une diff√©rence significative entre les groupes."
        else:
            result += "\nIl n'y a pas de diff√©rence significative entre les groupes."
        test_results.append(result)
    else:
        u_stat, p_value = stats.mannwhitneyu(df_area_non_0[var], df_area_0[var])
        result = f"Test de Mann-Whitney pour {var} - Statistique U : {u_stat:.3f}, p-value : {p_value:.3f}"
        if p_value < 0.05:
            result += "\nIl y a une diff√©rence significative entre les groupes."
        else:
            result += "\nIl n'y a pas de diff√©rence significative entre les groupes."
        test_results.append(result)

    test_results.append("-" * 50)

# Sauvegarder tous les r√©sultats dans un fichier PDF
save_results_to_pdf(test_results, save_dir, file_name="results_stats_inferentielles_tmw.pdf")

print("Les r√©sultats ont √©t√© sauvegard√©s dans un fichier PDF.")

# Test du Chi2
#save_dir = "statistiques_inf√©rentielles"
#os.makedirs(save_dir, exist_ok=True)

# üîπ Convertir X et Y en cat√©gories pour le test du Chi¬≤
df_area_non_0["X_cat"] = df_area_non_0["X"].astype("category")
df_area_non_0["Y_cat"] = df_area_non_0["Y"].astype("category")

# üîπ Effectuer les tests du Chi¬≤ et stocker les r√©sultats
results = []

for col in ["month", "day", "X_cat", "Y_cat"]:
    contingency_table = pd.crosstab(df_area_non_0[col], df_area_non_0["area"] > 0)
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    # Interpr√©tation du r√©sultat
    if p < 0.05:
        interpretation = f"Il y a une relation significative entre {col} et la pr√©sence d'un incendie (p = {p:.4f})."
    else:
        interpretation = f"Aucune relation significative d√©tect√©e entre {col} et la pr√©sence d'un incendie (p = {p:.4f})."

    # Stocker le r√©sultat
    results.append((col, chi2, p, dof, interpretation))

# üîπ Cr√©ation du PDF
pdf_path = os.path.join(save_dir, "chi2_results.pdf")

with PdfPages(pdf_path) as pdf:
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.axis("off")

    # Titre du rapport
    text = "Test du Chi¬≤ : Analyse des relations entre variables cat√©goriques et pr√©sence d'incendie\n\n"
    text += "\n".join([f"{col}: {interp}" for col, _, p, _, interp in results])

    ax.text(0, 1, text, fontsize=12, va="top")

    pdf.savefig(fig)
    plt.close()

print(f"Rapport du test du Chi¬≤ sauvegard√© dans {pdf_path}")

# maintenant regarder opportunit√© transformation log area, puis faire autres test statistiques inf√©rentielles avec Python/R
# puis faire si possible et autres analyses pouss√©es pour arriver √† √©tablir relations avec param√®tres m√©t√©o
# regarder les tests possibles pour savoir si relation non lin√©aire et l'√©tablir
#puis envisager de lancer des mod√®les types PCA, clustering, r√©gression logistique, random forest et autres mod√®les avec R, Python Scikit learn et autres
# ensuite regarder s'il faut enlever des outliers
# regarder aussi √©tablissement d'une √©chelle de risque avec les relations trouv√©es et FWI
# puis faire l'injection d'une base de donn√©es propre avec donn√©es cl√©s et trouv√©es et propres vers postgresql

# ANOVA et test de Kruskal-Wallis pour comparer surfaces brul√©es selon cat√©gories des diff√©rentes colonnes

# Liste des variables continues (excluant area et log_area)
variables_continues = ['X', 'Y', 'BUI', 'temp', 'FFMC', 'DMC', 'DC', 'ISI', 'RH', 'wind']

# Dictionnaire pour stocker les r√©sultats
test_results = []

# üìå Cat√©gorisation des variables continues en classes
df_area_0_cat = df_area_0.copy()
df_area_non_0_cat = df_area_non_0.copy()

for var in variables_continues:
    df_area_0_cat[var + "_cat"] = pd.qcut(df_area_0[var], q=3, labels=["Bas", "Moyen", "√âlev√©"])
    df_area_non_0_cat[var + "_cat"] = pd.qcut(df_area_non_0[var], q=3, labels=["Bas", "Moyen", "√âlev√©"])

# üìå S√©paration des variables normales et asym√©triques via le test de Shapiro-Wilk
variables_normales = []
variables_asymetriques = []

for var in variables_continues:
    p_value_non_0 = stats.shapiro(df_area_non_0[var])[1] if len(df_area_non_0[var]) > 3 else 1
    p_value_0 = stats.shapiro(df_area_0[var])[1] if len(df_area_0[var]) > 3 else 1

    if p_value_non_0 > 0.05 and p_value_0 > 0.05:
        variables_normales.append(var)
    else:
        variables_asymetriques.append(var)

# üìå ANOVA pour les variables normales
for var in variables_normales:
    f_stat, p_value = stats.f_oneway(df_area_non_0[var], df_area_0[var])
    result = f"ANOVA pour {var} : F = {f_stat:.3f}, p-value = {p_value:.3f}"
    result += "\n-> Diff√©rence significative entre les groupes." if p_value < 0.05 else "\n-> Aucune diff√©rence significative."
    test_results.append(result)

# üìå Kruskal-Wallis pour les variables asym√©triques
for var in variables_asymetriques:
    h_stat, p_value = stats.kruskal(df_area_non_0[var], df_area_0[var])
    result = f"Kruskal-Wallis pour {var} : H = {h_stat:.3f}, p-value = {p_value:.3f}"
    result += "\n-> Diff√©rence significative entre les groupes." if p_value < 0.05 else "\n-> Aucune diff√©rence significative."
    test_results.append(result)

# üìå Sauvegarde des r√©sultats dans un PDF
pdf = FPDF()
pdf.set_auto_page_break(auto=True, margin=15)
pdf.add_page()
pdf.set_font("Arial", size=12)

pdf.cell(200, 10, "R√©sultats des tests ANOVA et Kruskal-Wallis", ln=True, align='C')
pdf.ln(10)

for res in test_results:
    pdf.multi_cell(0, 10, res)
    pdf.ln(5)

pdf_file = os.path.join(save_dir, "anova_kruskal_results.pdf")
pdf.output(pdf_file)

print(f"Les r√©sultats ont √©t√© sauvegard√©s dans {pdf_file}.")

# Analyses statistiques compl√©mentaires avec R

# Activer la conversion entre pandas et R
pandas2ri.activate()

# Importer les packages R n√©cessaires
base = importr('base')
stats = importr('stats')
ggplot2 = importr('ggplot2')
cluster = importr('cluster')
forecast = importr('forecast')

# Convertir le dataframe pandas en dataframe R
df_r = pandas2ri.py2rpy(df_cleaned)

# 1. Test de normalit√© (Shapiro-Wilk et Kolmogorov-Smirnov) sur FWI
print("\nTest de normalit√© en R :")
shapiro_test = stats.shapiro_test(df_r.rx2("FWI"))
ks_test = stats.ks_test(df_r.rx2("FWI"), "pnorm", mean=df_cleaned['FWI'].mean(), sd=df_cleaned['FWI'].std())
print(f"Shapiro-Wilk p-value : {shapiro_test[1]}")
print(f"Kolmogorov-Smirnov p-value : {ks_test[1]}")

# 2. ANOVA (Analyse de la variance) pour tester les diff√©rences entre les saisons
print("\nAnalyse de la variance (ANOVA) en R :")
anova_model = stats.aov(r('FWI ~ season'), data=df_r)
print(base.summary(anova_model))

# 3. R√©gression non lin√©aire (polynomiale) entre FWI et Temp√©rature
print("\nR√©gression polynomiale en R :")
poly_model = stats.lm(r('FWI ~ poly(temp, 2)'), data=df_r)
print(base.summary(poly_model))

# 4. R√©gression multiple entre Temp√©rature et Humidit√© relative (avec la surface br√ªl√©e non nulle)
df_r_area_non_0 = pandas2ri.py2rpy(df_area_non_0)

# temp et rh sont les variables explicatives
print("\nR√©gression multiple en R : Temp√©rature et Humidit√© relative sur surface br√ªl√©e non nulle")

# Passer l'objet √† R pour la transformation et le mod√®le
#r('df_r_area_non_0 <- ' + str(df_r_area_non_0))  # Importer correctement le DataFrame dans R

# Transformer 'RH' en log(RH) car distribution asym√©trique
#r('df_r_area_non_0$log_RH <- log(df_r_area_non_0$RH)')

# Cr√©er le mod√®le de r√©gression multiple
lm_model_rh_temp = r.lm('log_area ~ temp + RH', data=df_r_area_non_0)

# Afficher le r√©sum√© du mod√®le
#print(r.summary(lm_model_rh_temp))

# R√©sum√© du mod√®le
print(base.summary(lm_model_rh_temp))

# R√©gression multiple entre BUI et Temp√©rature comme variables explicatives pour pr√©dire la surface br√ªl√©e
print("\nR√©gression multiple en R : BUI et Temp√©rature sur surface br√ªl√©e")

# Cr√©ation du mod√®le de r√©gression multiple
lm_model_temp_bui = r.lm('log_area ~ temp + BUI', data=df_r_area_non_0)

# R√©sum√© du mod√®le
print(base.summary(lm_model_temp_bui))


""""# 4. Clustering hi√©rarchique pour regrouper les jours selon leurs FWI et conditions
print("\nClustering hi√©rarchique en R :")
clustering_model = cluster.hclust(stats.dist(df_r.rx2("FWI")), method="ward.D2")
r("plot")(clustering_model, main="Clustering hi√©rarchique des FWI", sub="", xlab="Jours")

# 5. R√©sultat du clustering
cluster_assignments = r.cutree(clustering_model, k=3)
print("Cluster assignments :", cluster_assignments)"""

# 4 Cr√©ation et Alimentation de la Base de donn√©es trait√©e en utilisant PostGreSQL depuis Python

# Rappel des informations sur le dataframe trait√© √† l'√©tape 2
print("Rappel des informations sur le dataframe df_cleaned")
print(df_cleaned.info())

# Convertir la colonne 'season' en cha√Ænes de caract√®res
df_cleaned['day'] = df_cleaned['day'].astype(str)
df_cleaned['month'] = df_cleaned['month'].astype(str)
df_cleaned['season'] = df_cleaned['season'].astype(str)
df_cleaned['danger_level'] = df_cleaned['danger_level'].astype(str)
df_cleaned['level_description'] = df_cleaned['level_description'].astype(str)

# Connexion √† PostgreSQL (connexion √† la base par d√©faut 'postgres' pour cr√©er une nouvelle base)
def create_database(database_name, user, password, host, port):
    connection = psycopg2.connect(
        dbname='postgres',
        user=user,
        password=password,
        host=host,
        port=port
    )
    connection.autocommit = True
    cursor = connection.cursor()

    try:
        cursor.execute(sql.SQL("CREATE DATABASE {}").format(sql.Identifier(database_name)))
        print(f"La base de donn√©es '{database_name}' a √©t√© cr√©√©e avec succ√®s.")
    except psycopg2.errors.DuplicateDatabase:
        print(f"La base de donn√©es '{database_name}' existe d√©j√†.")

    cursor.close()
    connection.close()


# Connexion √† la base de donn√©es PostgreSQL avec encodage UTF-8
def connect_to_database(database_name, user, password, host, port):
    return psycopg2.connect(
        dbname=database_name,
        user=user,
        password=password,
        host=host,
        port=port,
        client_encoding='UTF8'  # Assurez-vous que l'encodage est UTF-8
    )


# Cr√©er la table dans la base de donn√©es
def create_table(cur):
    table_creation_query = """
    CREATE TABLE IF NOT EXISTS data_table_4 (
        X INTEGER,
        Y INTEGER,
        month VARCHAR,
        day VARCHAR,
        FFMC FLOAT,
        DMC FLOAT,
        DC FLOAT,
        ISI FLOAT,
        temp FLOAT,
        RH INTEGER,
        wind FLOAT,
        rain FLOAT,
        area FLOAT,
        season VARCHAR,
        BUI FLOAT,
        FWI FLOAT,
        danger_level VARCHAR,
        level_description VARCHAR,
        log_area FLOAT
    );
    """
    cur.execute(table_creation_query)

#PRIMARY KEY (X, Y, month, day)

# Ins√©rer les donn√©es du DataFrame dans la table
def insert_data_from_dataframe(cur, df):
    # Convertir le DataFrame en une liste de tuples
    data_tuples = [tuple(row) for row in df[['X', 'Y', 'month', 'day', 'FFMC', 'DMC', 'DC', 'ISI',
                                             'temp', 'RH', 'wind', 'rain', 'area', 'season',
                                             'BUI', 'FWI', 'danger_level', 'level_description',
                                             'log_area']].values]

    insert_query = """
    INSERT INTO data_table_4 (
        X, Y, month, day, FFMC, DMC, DC, ISI, temp, RH, wind, rain, area,
        season, BUI, FWI, danger_level, level_description, log_area
    ) VALUES %s;
    """

    # Insertion des donn√©es en une seule requ√™te
    execute_values(cur, insert_query, data_tuples)


# Param√®tres de connexion
database_name = "viken_db_4"  # Nom de votre base de donn√©es
user = "postgres"  # Votre utilisateur PostgreSQL
password = "formationviken"  # Votre mot de passe PostgreSQL
host = "localhost"  # H√¥te PostgreSQL (ici localhost)
port = "5432"  # Port PostgreSQL

# Cr√©er la base de donn√©es et ins√©rer les donn√©es
try:
    # 1. Cr√©er la base de donn√©es si elle n'existe pas
    create_database(database_name, user, password, host, port)

    # 2. Connecter √† la base de donn√©es nouvellement cr√©√©e
    conn = connect_to_database(database_name, user, password, host, port)
    cur = conn.cursor()

    # 3. Cr√©er la table si elle n'existe pas
    create_table(cur)

    # 4. Ins√©rer les donn√©es depuis le DataFrame
    insert_data_from_dataframe(cur, df_cleaned)

    # Commit des modifications
    conn.commit()

    print("Donn√©es ins√©r√©es avec succ√®s.")

except Exception as e:
    print(f"Erreur d'ex√©cution : {e}")

finally:
    # Fermer la connexion et le curseur
    if cur:
        cur.close()
    if conn:
        conn.close()
